#!/bin/bash
# Gather command line args
job_name=$1
input=$2
output=$3

echo "Updating virtualenv"
pip install -r requirements.txt --upgrade

echo "Zipping up virtualenv"
cd /home/halfak/venv/3.4/
zip -rq ../3.4.zip *
cd -
cp /home/halfak/venv/3.4.zip virtualenv.zip

echo "Moving virtualenv.zip to HDFS"
hdfs dfs -put -f virtualenv.zip /user/halfak/virtualenv.zip

echo "Running hadoop job"
hadoop jar /opt/hadoop/share/hadoop/tools/lib/hadoop-*streaming*.jar \
    -D  mapreduce.job.name=$job_name \
    -d  mapreduce.input.fileinputformat.split.minsize=9999999999999 \
    -D  mapreduce.output.fileoutputformat.compress=true \
    -D  mapreduce.output.fileoutputformat.compress.type=BLOCK \
    -D  mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.BZip2Codec \
    -D  mapreduce.task.timeout=6000000 \
    -D  mapreduce.map.memory.mb=1024 \
    -D  mapreduce.reduce.speculative=false \
    -D  mapreduce.reduce.memory.mb=1024 \
    -D  mapreduce.reduce.vcores=2 \
    -D  mapreduce.job.reduces=0 \
    -files       hadoop/mwpersistence \
    -archives    'hdfs:///user/halfak/virtualenv.zip#virtualenv' \
    -input       $input \
    -output      $output \
    -mapper      "./mwpersistence persistemce2stats --verbose"
