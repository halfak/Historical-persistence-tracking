#!/bin/bash
# Gather command line args
job_name=$1
sunset=$2
input=$3
output=$4

echo "Zipping up virtualenv"
cd virtualenv/
zip -rq ../virtualenv.zip *
cd ../

echo "Moving virtualenv.zip to HDFS"
hdfs dfs -put -f virtualenv.zip /user/halfak/hadoopin/virtualenv.zip;

echo "Running hadoop job"
hadoop jar /usr/lib/hadoop-mapreduce/hadoop-streaming.jar \
    -D  mapreduce.job.name=$job_name \
    -D  mapreduce.output.fileoutputformat.compress=true \
    -D  mapreduce.output.fileoutputformat.compress.type=BLOCK \
    -D  mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.SnappyCodec \
    -D  mapreduce.task.timeout=6000000 \
    -D  stream.num.map.output.key.fields=3 \
    -D  mapreduce.partition.keypartitioner.options='-k1,1n' \
    -D  mapreduce.job.output.key.comparator.class="org.apache.hadoop.mapred.lib.KeyFieldBasedComparator" \
    -D  mapreduce.partition.keycomparator.options='-k1,1n -k2,2 -k3,3n' \
    -D  mapreduce.job.reduces=50 \
    -files       mwstream,$diff_config  \
    -archives    'hdfs:///user/halfak/hadoopin/virtualenv.zip#virtualenv' \
    -input       $input \
    -output      $output \
    -mapper      "./mwstream json2tsv page.id timestamp id -" \
    -reducer     "bash -c 'cut -f4 | ./mwstream diffs2persistence --sunset=$sunset'" \
    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner
